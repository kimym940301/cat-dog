# 개와 고양이로 나누기 위한 CNN 이미지 분류
## 캐글(Kaggle)의 개 고양이 이미지 분류 대회는 이미지 데이터셋을 이용한 딥러닝 모델링 경진대회입니다.

# 전처리
 
### 개 이미지 12,500개, 고양이 이미지 12,500개를 train/validation/test 용으로 분리하고, tensorflow의 ImageDataGenerator를 사용할 것이기 때문에 각 라벨(cat,dog)를 폴더별로 따로 분리하도록 하겠습니다.
 - ImageDataGenerator란 이미지 데이터 처리를 위한 유틸리티 클래스입니다. 이 클래스는 이미지 데이터에 대한 다양한 변환 및 증강 기능을 제공합니다. 이를 통해 모델의 학습 데이터를 늘리거나, 이미지의 다양한 특징을 추출하는 등의 작업을 수행할 수 있습니다. 이 클래스는 회전, 확대/축소, 가로/세로 이동, 반전, 밝기 조절 등의 기능을 제공하며 다양한 인자를 통해 이미지 변환 방법을 지정할 수 있습니다.

# 모델링
 - 처음 이미지의 크기를 (255, 255)로 가정하고,RGB 이미지를 처리하기 때문에 입력 채널의 개수는 3이며, 모델의 첫 번째 레이어는 8개의 필터를 사용하는 3x3 크기의 컨볼루션 레이어이며, ReLU 활성화 함수를 사용합니다.
 - Conv2D에서 추출된 특징 맵의 크기를 줄이고 모델의 일반화 성능을 향상시키기 위해여 다음으로 맥스 풀링(Max Pooling) 레이어를 추가 했습니다.
 - Conv2D 와 maxpooling을 반복하여 특징을 추출해 특징을 강조하고 크기를 줄여 비용 계산을 절감했습니다. 
 - Flatten 레이어를 추가하면서, 이전 레이어의 출력값이 1차원 벡터로 변환되어, 다음 레이어에서 사용할 수 있게 됩니다
 - Dense 레이어가 두 개 추가되어 있습니다. 첫 번째 Dense 레이어는 32개의 뉴런(neuron)을 가지고, 활성화 함수(activation function)로 ReLU 함수를 사용합니다. 이 레이어는 전체 입력 벡터를 32개의 출력 벡터로 변환하는 과정을 수행합니다.
 - ReLu는 입력값이 양수이면 그대로 출력하고, 음수이면 0을 출력하는 함수입니다. 비선형성을 가지며, 출력값이 항상 0 또는 양수이기 때문에 신경망의 학습 능력을 향상시키는 역할을 합니다. 또한, 연산이 간단하고 계산 속도가 빠르기 때문에 다른 활성화 함수보다 더 빠르게 학습할 수 있습니다.
 - 이후 Dropout을 추가 해줬습니다. Dropout은 랜덤하게 선택된 일부 뉴런을 무시하도록 만들어, 모델이 특정 뉴런에 과도하게 의존하지 않도록 합니다. 
 - 마지막 Dense 레이어는 입력 이미지가 개인지 고양이인지 이진 분류하는 작업을 담당하며, sigmoid 함수를 활성화 함수로 사용하여 출력값이 0.5 이상이면 개로 분류하고 0.5 미만이면 고양이로 분류합니다. 
 - 시그모이드 함수는 입력값이 작을수록 0에 수렴하고, 입력값이 크면 1에 수렴합니다. 그리고 중간값인 0.5를 기준으로 대칭적인 S자 형태를 띠는 함수입니다.
 - 모델의 compile은 optimizer = "adam", loss = "binary_crossentropy", metrics = "accuracy"로 설정하였습니다.
 - optimizer = adam은 모멘트(momentum) 기반 최적화 알고리즘인 momentum과 RMSProp 알고리즘을 합친 것입니다.모멘트 기반 최적화 알고리즘은 현재 기울기와 이전의 기울기를 모두 고려하여 학습 속도를 결정하는 방법입니다. 
 - loss = binary_crossentropy은 모델이 이진 분류 문제를 학습할 때, 예측값과 실제값 사이의 차이를 계산하여 모델의 오차를 줄이는 방향으로 최적화합니다.예측값과 실제값 간의 차이를 계산하기 위해 로그 함수를 사용하며, 실제값이 1일 때 예측값이 0에 가깝다면 오차가 크게 계산되며, 반대로 실제값이 0일 때 예측값이 1에 가깝다면 오차가 크게 계산됩니다.
 - metrics = accuracy는 매개변수는 모델의 성능을 평가하는 데 사용되는 지표를 지정합니다. accuracy지표는 모델의 분류 정확도를 나타냅니다. 이 지표는 모델이 올바르게 분류된 샘플의 비율을 나타냅니다. 이진 분류 문제의 경우, accuracy는 실제 클래스와 예측 클래스가 일치하는 샘플의 비율을 나타냅니다.
 
 -모델 학습을 보다 효과적으로 제어하기 위해 callback 함수를 사용했습니다.
 - ModelCheckpoint : 모델의 성능이 가장 좋을 때마다 모델의 가중치를 저장하는 callback 함수입니다. save_best_only 매개변수를 True로 설정하여, 검증 데이터에서 가장 좋은 성능을 보인 모델의 가중치를 저장했습니다.
 - EarlyStopping: 모델의 성능이 일정 기간 동안 개선되지 않을 경우 학습을 조기 종료시키는 callback 함수입니다. patience 매개변수는 성능이 개선되지 않은 상태를에서 3번 허용할 것을 지정하였습니다.restore_best_weights 매개변수를 True로 설정하여 최적의 성능을 보였을 때 모델 가중치로 복원하였습니다.
 - ReduceLROnPlateau : 검증 손실이 개선되지 않을 경우 학습률을 조절하는 callback 함수입니다. monitor 매개변수를 검증손실 기준으로 학습률을 조율하였습니다. factor 매개변수를 .5로 설정하여 학습률을 감소시키고 , patience 매개변수로 성능이 개선되지 않는 3번의 상태를 허용 해주었습니다.
 
# 최적화
 - 기존 이미지 크기(255,255)에서 (128,128)로 줄여서 모델 학습에 필요한 계산량이 줄어들어 학습 속도가 빨라지게 했습니다.
 - 처음 Covd2D 다음 MaxPool(2)을 제거하므로 이미지의 공간적인 정보를 좀 더 획득하게 했습니다.
 - 모델링중 과적합이 발생하여 추가적으로 Dropout을 추가했습니다.
 - 중간 활성화 함수(activation function)의 ReLU 함수를 Leaky ReLU로 변경하였습니다. 그 이유는 ReLU(Rectified Linear Unit) 함수는 입력값이 0보다 작으면 출력값이 0이 되고, 0보다 큰 경우에는 입력값을 그대로 출력합니다. 이 때, 입력값이 음수인 경우에는 그대로 출력하기 때문에 'dying ReLU' 문제가 발생할 수 있습니다. 반면 Leaky ReLU(Leaky Rectified Linear Unit) 함수는 입력값이 음수일 경우에도 작은 양수 값을 출력합니다. 이 작은 양수 값을 출력함으로써 'dying ReLU' 문제를 완화할 수 있습니다. 
 - 이 작업들을 반복하여 좀 더 나은 모델을 구축하였습니다.
 
 # 최종
 - 베이스 모델 : loss: 0.4268 - accuracy: 0.8057 - val_loss: 0.3965 - val_accuracy: 0.8240  ***결과 : 0.36311 - 887등***
 - 최종 모델 : loss: 0.1407 - accuracy: 0.9443 - val_loss: 0.1747 - val_accuracy: 0.9284 - lr: 5.0000e-04 ***결과 : Score: 0.19314 - 776등***
